# æ¨¡åž‹ä¸‹è½½å’Œéƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜Žå¦‚ä½•ä¸‹è½½å’Œéƒ¨ç½² Local RAG ç³»ç»Ÿæ‰€éœ€çš„æ¨¡åž‹æ–‡ä»¶ã€‚

## ðŸ“‹ æ¨¡åž‹æ¦‚è§ˆ

Local RAG ç³»ç»Ÿä½¿ç”¨ä¸¤ä¸ªé¢„è®­ç»ƒæ¨¡åž‹ï¼š

| æ¨¡åž‹ | ç”¨é€” | å¤§å° | æ¥æº |
|------|------|------|------|
| bge-small-zh-v1.5 | æ–‡æœ¬åµŒå…¥ | ~400MB | BAAI/bge-small-zh-v1.5 |
| bge-reranker-base | ç»“æžœé‡æŽ’åº | ~1.1GB | BAAI/bge-reranker-base |

## ðŸš€ å¿«é€Ÿéƒ¨ç½²

### æ–¹æ³•ä¸€ï¼šè‡ªåŠ¨ä¸‹è½½è„šæœ¬ï¼ˆæŽ¨èï¼‰

åˆ›å»ºå¹¶è¿è¡Œä»¥ä¸‹è„šæœ¬ï¼š

```bash
# åˆ›å»º download_models.py
cat > download_models.py << 'EOF'
#!/usr/bin/env python3
"""
Local RAG æ¨¡åž‹è‡ªåŠ¨ä¸‹è½½è„šæœ¬
"""

import os
import sys
from pathlib import Path
from huggingface_hub import snapshot_download
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def download_model(repo_id: str, local_dir: Path, description: str):
    """ä¸‹è½½å•ä¸ªæ¨¡åž‹"""
    try:
        logger.info(f"å¼€å§‹ä¸‹è½½ {description}...")
        logger.info(f"ä»“åº“: {repo_id}")
        logger.info(f"ç›®æ ‡ç›®å½•: {local_dir}")
        
        # åˆ›å»ºç›®å½•
        local_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½æ¨¡åž‹
        snapshot_download(
            repo_id=repo_id,
            local_dir=str(local_dir),
            local_dir_use_symlinks=False,
            resume_download=True
        )
        
        logger.info(f"âœ… {description} ä¸‹è½½å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ {description} ä¸‹è½½å¤±è´¥: {e}")
        return False

def verify_model(model_dir: Path, model_name: str):
    """éªŒè¯æ¨¡åž‹æ–‡ä»¶å®Œæ•´æ€§"""
    required_files = [
        "config.json",
        "pytorch_model.bin",
        "tokenizer.json",
        "tokenizer_config.json"
    ]
    
    missing_files = []
    for file_name in required_files:
        file_path = model_dir / file_name
        if not file_path.exists():
            missing_files.append(file_name)
    
    if missing_files:
        logger.warning(f"âš ï¸  {model_name} ç¼ºå°‘æ–‡ä»¶: {missing_files}")
        return False
    else:
        logger.info(f"âœ… {model_name} æ–‡ä»¶å®Œæ•´")
        return True

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹ä¸‹è½½ Local RAG ç³»ç»Ÿæ¨¡åž‹...")
    
    # æ¨¡åž‹é…ç½®
    models = [
        {
            "repo_id": "BAAI/bge-small-zh-v1.5",
            "local_dir": Path("models/bge-small-zh-v1.5"),
            "description": "ä¸­æ–‡åµŒå…¥æ¨¡åž‹ (bge-small-zh-v1.5)"
        },
        {
            "repo_id": "BAAI/bge-reranker-base",
            "local_dir": Path("models/bge-reranker-base"),
            "description": "é‡æŽ’åºæ¨¡åž‹ (bge-reranker-base)"
        }
    ]
    
    # æ£€æŸ¥ç½‘ç»œè¿žæŽ¥
    try:
        import requests
        response = requests.get("https://huggingface.co", timeout=10)
        if response.status_code != 200:
            logger.error("âŒ æ— æ³•è¿žæŽ¥åˆ° Hugging Faceï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥")
            sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ç½‘ç»œè¿žæŽ¥æ£€æŸ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    # ä¸‹è½½æ¨¡åž‹
    success_count = 0
    for model in models:
        if download_model(model["repo_id"], model["local_dir"], model["description"]):
            if verify_model(model["local_dir"], model["description"]):
                success_count += 1
    
    # æ€»ç»“
    logger.info(f"æ¨¡åž‹ä¸‹è½½å®Œæˆ: {success_count}/{len(models)} æˆåŠŸ")
    
    if success_count == len(models):
        logger.info("ðŸŽ‰ æ‰€æœ‰æ¨¡åž‹ä¸‹è½½æˆåŠŸï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
        
        # æ˜¾ç¤ºæ¨¡åž‹ä¿¡æ¯
        logger.info("\nðŸ“Š æ¨¡åž‹ä¿¡æ¯:")
        for model in models:
            model_dir = model["local_dir"]
            if model_dir.exists():
                size = sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file())
                size_mb = size / (1024 * 1024)
                logger.info(f"  - {model['description']}: {size_mb:.1f} MB")
    else:
        logger.error("âŒ éƒ¨åˆ†æ¨¡åž‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")
        sys.exit(1)

if __name__ == "__main__":
    main()
EOF

# å®‰è£…ä¾èµ–å¹¶è¿è¡Œ
pip install huggingface_hub requests
python download_models.py
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨ huggingface-cli

```bash
# å®‰è£… huggingface_hub
pip install huggingface_hub

# ä¸‹è½½åµŒå…¥æ¨¡åž‹
huggingface-cli download BAAI/bge-small-zh-v1.5 --local-dir models/bge-small-zh-v1.5

# ä¸‹è½½é‡æŽ’åºæ¨¡åž‹
huggingface-cli download BAAI/bge-reranker-base --local-dir models/bge-reranker-base
```

### æ–¹æ³•ä¸‰ï¼šä½¿ç”¨ git-lfs

```bash
# å®‰è£… git-lfs
git lfs install

# åˆ›å»ºæ¨¡åž‹ç›®å½•
mkdir -p models

# å…‹éš†åµŒå…¥æ¨¡åž‹
cd models
git clone https://huggingface.co/BAAI/bge-small-zh-v1.5
git clone https://huggingface.co/BAAI/bge-reranker-base
cd ..
```

## ðŸ”§ æ‰‹åŠ¨ä¸‹è½½

å¦‚æžœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ¨¡åž‹æ–‡ä»¶ï¼š

### 1. åµŒå…¥æ¨¡åž‹ (bge-small-zh-v1.5)

è®¿é—® https://huggingface.co/BAAI/bge-small-zh-v1.5/tree/main

ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶åˆ° `models/bge-small-zh-v1.5/` ç›®å½•ï¼š

```text
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â”œâ”€â”€ sentence_bert_config.json
â”œâ”€â”€ special_tokens_map.json
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â””â”€â”€ vocab.txt
```

### 2. é‡æŽ’åºæ¨¡åž‹ (bge-reranker-base)

è®¿é—® https://huggingface.co/BAAI/bge-reranker-base/tree/main

ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶åˆ° `models/bge-reranker-base/` ç›®å½•ï¼š

```text
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â”œâ”€â”€ special_tokens_map.json
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â””â”€â”€ vocab.txt
```

## âœ… éªŒè¯å®‰è£…

### 1. æ£€æŸ¥æ–‡ä»¶ç»“æž„

```bash
# æ£€æŸ¥ç›®å½•ç»“æž„
tree models/

# é¢„æœŸè¾“å‡ºï¼š
# models/
# â”œâ”€â”€ bge-small-zh-v1.5/
# â”‚   â”œâ”€â”€ config.json
# â”‚   â”œâ”€â”€ pytorch_model.bin
# â”‚   â”œâ”€â”€ sentence_bert_config.json
# â”‚   â”œâ”€â”€ special_tokens_map.json
# â”‚   â”œâ”€â”€ tokenizer.json
# â”‚   â”œâ”€â”€ tokenizer_config.json
# â”‚   â””â”€â”€ vocab.txt
# â””â”€â”€ bge-reranker-base/
#     â”œâ”€â”€ config.json
#     â”œâ”€â”€ pytorch_model.bin
#     â”œâ”€â”€ special_tokens_map.json
#     â”œâ”€â”€ tokenizer.json
#     â”œâ”€â”€ tokenizer_config.json
#     â””â”€â”€ vocab.txt
```

### 2. éªŒè¯æ¨¡åž‹åŠ è½½

```bash
# åˆ›å»ºéªŒè¯è„šæœ¬
cat > verify_models.py << 'EOF'
#!/usr/bin/env python3
"""
æ¨¡åž‹éªŒè¯è„šæœ¬
"""

import sys
from pathlib import Path
from sentence_transformers import SentenceTransformer

def test_model(model_path: str, model_name: str):
    """æµ‹è¯•æ¨¡åž‹åŠ è½½"""
    try:
        print(f"æµ‹è¯• {model_name}...")
        model = SentenceTransformer(model_path)
        
        # æµ‹è¯•ç¼–ç 
        if "reranker" in model_path:
            # é‡æŽ’åºæ¨¡åž‹æµ‹è¯•
            scores = model.compute_score([["æŸ¥è¯¢æ–‡æœ¬", "ç›¸å…³æ–‡æ¡£"]])
            print(f"  âœ… é‡æŽ’åºæµ‹è¯•æˆåŠŸï¼Œåˆ†æ•°: {scores}")
        else:
            # åµŒå…¥æ¨¡åž‹æµ‹è¯•
            embeddings = model.encode(["æµ‹è¯•æ–‡æœ¬"])
            print(f"  âœ… åµŒå…¥æµ‹è¯•æˆåŠŸï¼Œç»´åº¦: {embeddings.shape}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ {model_name} åŠ è½½å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("éªŒè¯æ¨¡åž‹å®‰è£…...")
    
    models = [
        ("models/bge-small-zh-v1.5", "åµŒå…¥æ¨¡åž‹"),
        ("models/bge-reranker-base", "é‡æŽ’åºæ¨¡åž‹")
    ]
    
    success_count = 0
    for model_path, model_name in models:
        if Path(model_path).exists():
            if test_model(model_path, model_name):
                success_count += 1
        else:
            print(f"  âŒ {model_name} ç›®å½•ä¸å­˜åœ¨: {model_path}")
    
    print(f"\néªŒè¯ç»“æžœ: {success_count}/{len(models)} æ¨¡åž‹å¯ç”¨")
    
    if success_count == len(models):
        print("ðŸŽ‰ æ‰€æœ‰æ¨¡åž‹éªŒè¯æˆåŠŸï¼")
        return True
    else:
        print("âŒ éƒ¨åˆ†æ¨¡åž‹éªŒè¯å¤±è´¥")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
EOF

# è¿è¡ŒéªŒè¯
python verify_models.py
```

### 3. ç³»ç»Ÿé…ç½®éªŒè¯

```bash
# ä½¿ç”¨ç³»ç»Ÿé…ç½®éªŒè¯
python -c "
from app.core.config import settings
import sys

print('éªŒè¯ç³»ç»Ÿé…ç½®...')
validation = settings.validate_paths()

for key, status in validation.items():
    status_icon = 'âœ…' if status else 'âŒ'
    print(f'{status_icon} {key}: {status}')

if all(validation.values()):
    print('ðŸŽ‰ ç³»ç»Ÿé…ç½®éªŒè¯æˆåŠŸï¼')
    sys.exit(0)
else:
    print('âŒ ç³»ç»Ÿé…ç½®éªŒè¯å¤±è´¥')
    sys.exit(1)
"
```

## ðŸ”§ æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ä¸‹è½½é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä½¿ç”¨é•œåƒç«™ç‚¹
export HF_ENDPOINT=https://hf-mirror.com
python download_models.py

# æˆ–ä½¿ç”¨ä»£ç†
export HTTP_PROXY=http://your-proxy:port
export HTTPS_PROXY=http://your-proxy:port
python download_models.py
```

#### 2. ç£ç›˜ç©ºé—´ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ¸…ç†ä¸å¿…è¦çš„æ–‡ä»¶
# æ¨¡åž‹æ€»å¤§å°çº¦ 1.5GBï¼Œç¡®ä¿è‡³å°‘æœ‰ 3GB å¯ç”¨ç©ºé—´
```

#### 3. ç½‘ç»œè¿žæŽ¥é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æµ‹è¯•ç½‘ç»œè¿žæŽ¥
curl -I https://huggingface.co

# å¦‚æžœæ— æ³•è¿žæŽ¥ï¼Œè€ƒè™‘ä½¿ç”¨ç¦»çº¿ä¸‹è½½æ–¹å¼
# æˆ–è”ç³»ç½‘ç»œç®¡ç†å‘˜
```

#### 4. æƒé™é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥ç›®å½•æƒé™
ls -la models/

# ä¿®å¤æƒé™
chmod -R 755 models/
chown -R $USER:$USER models/
```

#### 5. æ¨¡åž‹æ–‡ä»¶æŸå

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# åˆ é™¤æŸåçš„æ¨¡åž‹æ–‡ä»¶
rm -rf models/bge-small-zh-v1.5
rm -rf models/bge-reranker-base

# é‡æ–°ä¸‹è½½
python download_models.py
```

## ðŸ“Š æ¨¡åž‹æ€§èƒ½å¯¹æ¯”

| æ¨¡åž‹ | å‚æ•°é‡ | å†…å­˜å ç”¨ | æŽ¨ç†é€Ÿåº¦ | ä¸­æ–‡æ•ˆæžœ |
|------|--------|----------|----------|----------|
| bge-small-zh-v1.5 | 33M | ~400MB | å¿« | ä¼˜ç§€ |
| bge-base-zh-v1.5 | 102M | ~1.2GB | ä¸­ç­‰ | æ›´ä¼˜ç§€ |
| bge-large-zh-v1.5 | 326M | ~3.8GB | æ…¢ | æœ€ä¼˜ç§€ |

**æ³¨æ„**ï¼šé»˜è®¤ä½¿ç”¨ small ç‰ˆæœ¬ä»¥å¹³è¡¡æ€§èƒ½å’Œèµ„æºå ç”¨ã€‚å¦‚éœ€æ›´å¥½æ•ˆæžœï¼Œå¯æ›¿æ¢ä¸º base æˆ– large ç‰ˆæœ¬ã€‚

## ðŸ”„ æ¨¡åž‹æ›´æ–°

### æ£€æŸ¥æ¨¡åž‹ç‰ˆæœ¬

```bash
# æ£€æŸ¥å½“å‰æ¨¡åž‹ç‰ˆæœ¬
python -c "
import json
from pathlib import Path

for model_dir in ['models/bge-small-zh-v1.5', 'models/bge-reranker-base']:
    config_path = Path(model_dir) / 'config.json'
    if config_path.exists():
        with open(config_path) as f:
            config = json.load(f)
        print(f'{model_dir}: {config.get(\"_name_or_path\", \"æœªçŸ¥ç‰ˆæœ¬\")}')
"
```

### æ›´æ–°æ¨¡åž‹

```bash
# å¤‡ä»½å½“å‰æ¨¡åž‹
mv models models_backup_$(date +%Y%m%d)

# é‡æ–°ä¸‹è½½æœ€æ–°ç‰ˆæœ¬
python download_models.py

# éªŒè¯æ–°æ¨¡åž‹
python verify_models.py
```

## ðŸ“ è‡ªå®šä¹‰æ¨¡åž‹

å¦‚æžœéœ€è¦ä½¿ç”¨å…¶ä»–æ¨¡åž‹ï¼Œè¯·ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š

```python
# app/core/config.py
class Settings(BaseSettings):
    # ä¿®æ”¹æ¨¡åž‹ç›®å½•å
    EMBEDDING_MODEL_DIR: str = "your-custom-embedding-model"
    RERANKER_MODEL_DIR: str = "your-custom-reranker-model"
```

ç¡®ä¿è‡ªå®šä¹‰æ¨¡åž‹ä¸Ž sentence-transformers å…¼å®¹ã€‚

---

**æç¤º**ï¼šé¦–æ¬¡ä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚å»ºè®®åœ¨ç½‘ç»œçŠ¶å†µè‰¯å¥½æ—¶è¿›è¡Œä¸‹è½½ã€‚