# æ•…éšœæ’é™¤å’Œå¸¸è§é—®é¢˜è§£ç­”

æœ¬æ–‡æ¡£æä¾› Local RAG ç³»ç»Ÿå¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ¡ˆå’Œæ•…éšœæ’é™¤æŒ‡å—ã€‚

## ğŸš¨ ç´§æ€¥æ•…éšœå¤„ç†

### ç³»ç»Ÿæ— æ³•å¯åŠ¨

**ç—‡çŠ¶**: è¿è¡Œ `python start_server.py` åç³»ç»Ÿå´©æºƒæˆ–æ— å“åº”

**å¿«é€Ÿè¯Šæ–­**:
```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version

# æ£€æŸ¥ä¾èµ–å®‰è£…
pip list | grep -E "(fastapi|torch|transformers|chromadb)"

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -la models/

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -n 50 logs/app.log
```

**å¸¸è§åŸå› å’Œè§£å†³æ–¹æ¡ˆ**:

1. **Python ç‰ˆæœ¬ä¸å…¼å®¹**
   ```bash
   # ç¡®ä¿ä½¿ç”¨ Python 3.13+
   python3.13 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

2. **æ¨¡å‹æ–‡ä»¶ç¼ºå¤±**
   ```bash
   # é‡æ–°ä¸‹è½½æ¨¡å‹
   python -c "
   from huggingface_hub import snapshot_download
   snapshot_download('BAAI/bge-small-zh-v1.5', local_dir='models/bge-small-zh-v1.5')
   snapshot_download('BAAI/bge-reranker-base', local_dir='models/bge-reranker-base')
   "
   ```

3. **ç«¯å£è¢«å ç”¨**
   ```bash
   # æŸ¥æ‰¾å ç”¨è¿›ç¨‹
   lsof -i :8000
   
   # æ€æ­»è¿›ç¨‹
   kill -9 <PID>
   
   # æˆ–ä½¿ç”¨ä¸åŒç«¯å£
   API_PORT=8001 python start_server.py
   ```

## ğŸ”§ å®‰è£…å’Œé…ç½®é—®é¢˜

### Q1: ä¾èµ–å®‰è£…å¤±è´¥

**é—®é¢˜**: `pip install -r requirements.txt` å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡çº§ pip
pip install --upgrade pip

# ä½¿ç”¨å›½å†…é•œåƒ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/

# åˆ†æ­¥å®‰è£…å…³é”®ä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install transformers sentence-transformers
pip install fastapi uvicorn chromadb jieba

# å¦‚æœä»ç„¶å¤±è´¥ï¼Œä½¿ç”¨ conda
conda create -n local-rag python=3.13
conda activate local-rag
conda install pytorch torchvision torchaudio cpuonly -c pytorch
pip install -r requirements.txt
```

### Q2: æ¨¡å‹ä¸‹è½½é€Ÿåº¦æ…¢æˆ–å¤±è´¥

**é—®é¢˜**: æ¨¡å‹ä¸‹è½½è¶…æ—¶æˆ–é€Ÿåº¦ææ…¢

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ³•1: ä½¿ç”¨é•œåƒç«™ç‚¹
export HF_ENDPOINT=https://hf-mirror.com
python download_models.py

# æ–¹æ³•2: ä½¿ç”¨ä»£ç†
export HTTP_PROXY=http://your-proxy:port
export HTTPS_PROXY=http://your-proxy:port

# æ–¹æ³•3: æ‰‹åŠ¨ä¸‹è½½
# è®¿é—® https://hf-mirror.com/BAAI/bge-small-zh-v1.5
# ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ° models/bge-small-zh-v1.5/

# æ–¹æ³•4: ä½¿ç”¨ git-lfs
git lfs install
cd models
git clone https://hf-mirror.com/BAAI/bge-small-zh-v1.5
git clone https://hf-mirror.com/BAAI/bge-reranker-base
```

### Q3: æƒé™é”™è¯¯

**é—®é¢˜**: `Permission denied` é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç›®å½•æƒé™
ls -la

# ä¿®å¤æƒé™
chmod -R 755 models/ data/ logs/
chown -R $USER:$USER models/ data/ logs/

# å¦‚æœæ˜¯ Windowsï¼Œä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ
# æˆ–æ£€æŸ¥é˜²ç—…æ¯’è½¯ä»¶æ˜¯å¦é˜»æ­¢æ–‡ä»¶è®¿é—®
```

## ğŸ§  æ¨¡å‹ç›¸å…³é—®é¢˜

### Q4: æ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `ModelLoadError: æ— æ³•åŠ è½½åµŒå…¥æ¨¡å‹`

**è¯Šæ–­æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
python -c "
import os
from pathlib import Path

model_dir = Path('models/bge-small-zh-v1.5')
required_files = ['config.json', 'pytorch_model.bin', 'tokenizer.json']

for file in required_files:
    file_path = model_dir / file
    if file_path.exists():
        print(f'âœ… {file}: {file_path.stat().st_size} bytes')
    else:
        print(f'âŒ {file}: æ–‡ä»¶ä¸å­˜åœ¨')
"

# 2. æµ‹è¯•æ¨¡å‹åŠ è½½
python -c "
from sentence_transformers import SentenceTransformer
try:
    model = SentenceTransformer('models/bge-small-zh-v1.5')
    print('âœ… æ¨¡å‹åŠ è½½æˆåŠŸ')
    
    # æµ‹è¯•ç¼–ç 
    embeddings = model.encode(['æµ‹è¯•æ–‡æœ¬'])
    print(f'âœ… ç¼–ç æµ‹è¯•æˆåŠŸï¼Œç»´åº¦: {embeddings.shape}')
except Exception as e:
    print(f'âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}')
"
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. é‡æ–°ä¸‹è½½æ¨¡å‹
rm -rf models/bge-small-zh-v1.5
rm -rf models/bge-reranker-base
python download_models.py

# 2. æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# 3. æ£€æŸ¥å†…å­˜
free -h

# 4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚æœå†…å­˜ä¸è¶³ï¼‰
# ä¿®æ”¹ app/core/config.py ä¸­çš„æ¨¡å‹è·¯å¾„
```

### Q5: å†…å­˜ä¸è¶³é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: `OutOfMemoryError` æˆ–ç³»ç»Ÿå¡é¡¿

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥ç³»ç»Ÿå†…å­˜
free -h
htop

# 2. å‡å°‘æ¨¡å‹å†…å­˜å ç”¨
# åœ¨ app/core/config.py ä¸­æ·»åŠ ï¼š
# TORCH_DEVICE = "cpu"  # å¼ºåˆ¶ä½¿ç”¨ CPU
# MODEL_CACHE_SIZE = 1  # å‡å°‘ç¼“å­˜

# 3. è°ƒæ•´åˆ†ç‰‡å‚æ•°
# å‡å°‘ DEFAULT_CHUNK_SIZE å’Œ DEFAULT_RETRIEVAL_K

# 4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
# ä¸‹è½½ bge-small-zh è€Œä¸æ˜¯ bge-base-zh

# 5. å¢åŠ è™šæ‹Ÿå†…å­˜ï¼ˆLinuxï¼‰
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

## ğŸ’¾ æ•°æ®åº“é—®é¢˜

### Q6: ChromaDB è¿æ¥å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `DatabaseError: ChromaDB è¿æ¥å¤±è´¥`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥æ•°æ®ç›®å½•
ls -la data/chroma_db/

# 2. æ¸…ç†æŸåçš„æ•°æ®åº“
rm -rf data/chroma_db/*
mkdir -p data/chroma_db

# 3. æ£€æŸ¥æƒé™
chmod 755 data/chroma_db

# 4. æµ‹è¯•æ•°æ®åº“è¿æ¥
python -c "
import chromadb
try:
    client = chromadb.PersistentClient(path='data/chroma_db')
    collection = client.get_or_create_collection('test')
    print('âœ… ChromaDB è¿æ¥æˆåŠŸ')
except Exception as e:
    print(f'âŒ ChromaDB è¿æ¥å¤±è´¥: {e}')
"

# 5. å¦‚æœä»ç„¶å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜æ•°æ®åº“
# åœ¨é…ç½®ä¸­è®¾ç½® CHROMA_DB_PATH = ":memory:"
```

### Q7: æ•°æ®åº“æ–‡ä»¶æŸå

**ç—‡çŠ¶**: æŸ¥è¯¢è¿”å›ç©ºç»“æœæˆ–å¼‚å¸¸é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. å¤‡ä»½ç°æœ‰æ•°æ®
cp -r data/chroma_db data/chroma_db_backup_$(date +%Y%m%d)

# 2. æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
python -c "
import chromadb
import sqlite3

# æ£€æŸ¥ SQLite æ–‡ä»¶
db_path = 'data/chroma_db/chroma.sqlite3'
try:
    conn = sqlite3.connect(db_path)
    conn.execute('PRAGMA integrity_check;')
    print('âœ… æ•°æ®åº“æ–‡ä»¶å®Œæ•´')
    conn.close()
except Exception as e:
    print(f'âŒ æ•°æ®åº“æ–‡ä»¶æŸå: {e}')
"

# 3. é‡å»ºæ•°æ®åº“
rm -rf data/chroma_db
mkdir -p data/chroma_db

# 4. é‡æ–°å¯¼å…¥æ–‡æ¡£
python scripts/bulk_ingest.py --path documents/
```

## ğŸŒ API é—®é¢˜

### Q8: API è¯·æ±‚è¶…æ—¶

**é”™è¯¯ä¿¡æ¯**: `Request timeout` æˆ– `Connection timeout`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl -I http://localhost:8000/health

# 2. å¢åŠ è¶…æ—¶æ—¶é—´
curl -X POST "http://localhost:8000/api/v1/retrieve" \
  --max-time 60 \
  -H "Content-Type: application/json" \
  -d '{"query": "æµ‹è¯•æŸ¥è¯¢"}'

# 3. æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
top
iostat 1

# 4. ä¼˜åŒ–æŸ¥è¯¢å‚æ•°
# å‡å°‘ retrieval_k å’Œ top_k å‚æ•°

# 5. åœ¨å®¢æˆ·ç«¯ä»£ç ä¸­è®¾ç½®è¶…æ—¶
import requests
requests.post(url, json=data, timeout=60)
```

### Q9: API è¿”å› 422 é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: `Unprocessable Entity`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥è¯·æ±‚æ ¼å¼
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{
    "document_path": "/absolute/path/to/document.txt",
    "chunk_size": 300,
    "chunk_overlap": 50
  }' -v

# 2. éªŒè¯å‚æ•°ç±»å‹
# chunk_size å’Œ chunk_overlap å¿…é¡»æ˜¯æ•´æ•°
# document_path å¿…é¡»æ˜¯å­—ç¬¦ä¸²

# 3. æ£€æŸ¥æ–‡ä»¶è·¯å¾„
# ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»
ls -la /path/to/document.txt

# 4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{"invalid": "data"}' | jq .
```

### Q10: æ–‡æ¡£æ ¼å¼ä¸æ”¯æŒ

**é”™è¯¯ä¿¡æ¯**: `ValidationError: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥æ”¯æŒçš„æ ¼å¼
python -c "
from app.core.config import settings
print('æ”¯æŒçš„æ ¼å¼:', settings.SUPPORTED_FORMATS)
"

# 2. è½¬æ¢æ–‡æ¡£æ ¼å¼
# Word è½¬ txt
pandoc document.docx -o document.txt

# PDF è½¬ txt
pdftotext document.pdf document.txt

# HTML è½¬ txt
pandoc document.html -o document.txt

# 3. æ‰¹é‡è½¬æ¢
find documents/ -name "*.docx" -exec pandoc {} -o {}.txt \;

# 4. æ£€æŸ¥æ–‡ä»¶ç¼–ç 
file -i document.txt
# å¦‚æœä¸æ˜¯ UTF-8ï¼Œè½¬æ¢ç¼–ç 
iconv -f GBK -t UTF-8 document.txt > document_utf8.txt
```

## ğŸ“Š æ€§èƒ½é—®é¢˜

### Q11: æ£€ç´¢é€Ÿåº¦æ…¢

**ç—‡çŠ¶**: æŸ¥è¯¢å“åº”æ—¶é—´è¶…è¿‡ 5 ç§’

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```bash
# 1. è°ƒæ•´æ£€ç´¢å‚æ•°
# å‡å°‘å€™é€‰æ–‡æ¡£æ•°é‡
curl -X POST "http://localhost:8000/api/v1/retrieve" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "æµ‹è¯•æŸ¥è¯¢",
    "retrieval_k": 5,
    "top_k": 2
  }'

# 2. ä¼˜åŒ–åˆ†ç‰‡å¤§å°
# ä½¿ç”¨æ›´å¤§çš„åˆ†ç‰‡å‡å°‘æ€»æ•°é‡
python scripts/bulk_ingest.py --path documents/ --chunk-size 500

# 3. æ£€æŸ¥ç³»ç»Ÿèµ„æº
htop
iotop

# 4. ä½¿ç”¨ SSD å­˜å‚¨
# å°† data/ ç›®å½•ç§»åŠ¨åˆ° SSD

# 5. å¯ç”¨æ¨¡å‹ç¼“å­˜
# åœ¨é…ç½®ä¸­è®¾ç½®é€‚å½“çš„ç¼“å­˜å¤§å°
```

### Q12: å†…å­˜ä½¿ç”¨è¿‡é«˜

**ç—‡çŠ¶**: ç³»ç»Ÿå†…å­˜å ç”¨æŒç»­å¢é•¿

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. ç›‘æ§å†…å­˜ä½¿ç”¨
python -c "
import psutil
import os

process = psutil.Process(os.getpid())
print(f'å†…å­˜ä½¿ç”¨: {process.memory_info().rss / 1024 / 1024:.1f} MB')
"

# 2. é‡å¯æœåŠ¡é‡Šæ”¾å†…å­˜
pkill -f "python start_server.py"
python start_server.py

# 3. è°ƒæ•´é…ç½®å‡å°‘å†…å­˜ä½¿ç”¨
# åœ¨ app/core/config.py ä¸­ï¼š
# DEFAULT_RETRIEVAL_K = 5  # å‡å°‘æ£€ç´¢æ•°é‡
# DEFAULT_CHUNK_SIZE = 200  # å‡å°‘åˆ†ç‰‡å¤§å°

# 4. ä½¿ç”¨å†…å­˜åˆ†æå·¥å…·
pip install memory-profiler
python -m memory_profiler start_server.py

# 5. å¯ç”¨åƒåœ¾å›æ”¶
python -c "
import gc
gc.collect()
print('åƒåœ¾å›æ”¶å®Œæˆ')
"
```

## ğŸ” è°ƒè¯•å’Œæ—¥å¿—

### Q13: å¦‚ä½•å¯ç”¨è¯¦ç»†æ—¥å¿—

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. è®¾ç½®æ—¥å¿—çº§åˆ«
LOG_LEVEL=DEBUG python start_server.py

# 2. æŸ¥çœ‹ä¸åŒç±»å‹çš„æ—¥å¿—
tail -f logs/app.log        # åº”ç”¨æ—¥å¿—
tail -f logs/error.log      # é”™è¯¯æ—¥å¿—
tail -f logs/performance.log # æ€§èƒ½æ—¥å¿—

# 3. è¿‡æ»¤ç‰¹å®šç»„ä»¶çš„æ—¥å¿—
grep "DocumentProcessor" logs/app.log
grep "VectorRetriever" logs/app.log
grep "ModelLoader" logs/app.log

# 4. å®æ—¶ç›‘æ§æ—¥å¿—
tail -f logs/app.log | grep -E "(ERROR|WARNING)"
```

### Q14: å¦‚ä½•è°ƒè¯• API è¯·æ±‚

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. å¯ç”¨è¯·æ±‚è¿½è¸ª
# åœ¨æ—¥å¿—ä¸­æŸ¥çœ‹è¯·æ±‚ ID
grep "request_id" logs/app.log

# 2. ä½¿ç”¨ curl è¯¦ç»†æ¨¡å¼
curl -X POST "http://localhost:8000/api/v1/retrieve" \
  -H "Content-Type: application/json" \
  -d '{"query": "æµ‹è¯•"}' \
  -v

# 3. æ£€æŸ¥ API æ–‡æ¡£
# è®¿é—® http://localhost:8000/docs

# 4. ä½¿ç”¨ Python è°ƒè¯•
import requests
import logging

logging.basicConfig(level=logging.DEBUG)
response = requests.post(url, json=data)
```

## ğŸ”„ æ•°æ®è¿ç§»å’Œå¤‡ä»½

### Q15: å¦‚ä½•å¤‡ä»½å’Œæ¢å¤æ•°æ®

**å¤‡ä»½æ–¹æ¡ˆ**:
```bash
# 1. å®Œæ•´å¤‡ä»½
tar -czf local_rag_backup_$(date +%Y%m%d).tar.gz \
  data/ models/ logs/ app/core/config.py

# 2. ä»…å¤‡ä»½æ•°æ®åº“
cp -r data/chroma_db data/chroma_db_backup_$(date +%Y%m%d)

# 3. å¯¼å‡ºæ–‡æ¡£åˆ—è¡¨
python -c "
import chromadb
client = chromadb.PersistentClient(path='data/chroma_db')
collection = client.get_collection('documents')
metadata = collection.get(include=['metadatas'])
print('æ–‡æ¡£æ•°é‡:', len(metadata['metadatas']))
"

# 4. è‡ªåŠ¨å¤‡ä»½è„šæœ¬
cat > backup.sh << 'EOF'
#!/bin/bash
BACKUP_DIR="backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p $BACKUP_DIR
cp -r data/chroma_db $BACKUP_DIR/
echo "å¤‡ä»½å®Œæˆ: $BACKUP_DIR"
EOF
chmod +x backup.sh
```

**æ¢å¤æ–¹æ¡ˆ**:
```bash
# 1. æ¢å¤æ•°æ®åº“
rm -rf data/chroma_db
cp -r data/chroma_db_backup_20240101 data/chroma_db

# 2. éªŒè¯æ¢å¤
python -c "
import chromadb
client = chromadb.PersistentClient(path='data/chroma_db')
collections = client.list_collections()
print('é›†åˆæ•°é‡:', len(collections))
"

# 3. é‡æ–°ç´¢å¼•ï¼ˆå¦‚æœéœ€è¦ï¼‰
python scripts/bulk_ingest.py --path documents/
```

## ğŸš€ æ€§èƒ½è°ƒä¼˜

### ç³»ç»Ÿçº§ä¼˜åŒ–

```bash
# 1. è°ƒæ•´æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
ulimit -n 65536

# 2. ä¼˜åŒ– Python GC
export PYTHONHASHSEED=0
export PYTHONOPTIMIZE=1

# 3. ä½¿ç”¨æ›´å¿«çš„ JSON åº“
pip install orjson
# åœ¨ä»£ç ä¸­æ›¿æ¢ json ä¸º orjson

# 4. å¯ç”¨ JIT ç¼–è¯‘
pip install numba
# åœ¨è®¡ç®—å¯†é›†å‹å‡½æ•°ä¸Šä½¿ç”¨ @numba.jit

# 5. ä½¿ç”¨å¤šè¿›ç¨‹
# å¯åŠ¨å¤šä¸ª worker
uvicorn app.main:app --workers 4 --host 0.0.0.0 --port 8000
```

### åº”ç”¨çº§ä¼˜åŒ–

```python
# 1. è¿æ¥æ± é…ç½®
# åœ¨ app/core/config.py ä¸­ï¼š
CHROMA_POOL_SIZE = 10
MODEL_CACHE_SIZE = 100

# 2. æ‰¹é‡å¤„ç†
# æ‰¹é‡æ‘„å–æ–‡æ¡£è€Œä¸æ˜¯é€ä¸ªå¤„ç†

# 3. å¼‚æ­¥å¤„ç†
# ä½¿ç”¨ asyncio å¤„ç† I/O å¯†é›†å‹æ“ä½œ

# 4. ç¼“å­˜ç­–ç•¥
# ç¼“å­˜å¸¸ç”¨æŸ¥è¯¢ç»“æœ
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_retrieve(query_hash):
    # å®ç°ç¼“å­˜é€»è¾‘
    pass
```

## ğŸ“ è·å–å¸®åŠ©

### ç¤¾åŒºæ”¯æŒ

- **GitHub Issues**: æŠ¥å‘Š bug å’ŒåŠŸèƒ½è¯·æ±‚
- **è®¨è®ºåŒº**: æŠ€æœ¯è®¨è®ºå’Œç»éªŒåˆ†äº«
- **æ–‡æ¡£**: æŸ¥çœ‹æœ€æ–°æ–‡æ¡£å’Œæ•™ç¨‹

### æäº¤é—®é¢˜æ—¶è¯·åŒ…å«

1. **ç³»ç»Ÿä¿¡æ¯**:
   ```bash
   python --version
   pip list | grep -E "(torch|transformers|chromadb)"
   uname -a
   ```

2. **é”™è¯¯æ—¥å¿—**:
   ```bash
   tail -n 100 logs/app.log
   tail -n 50 logs/error.log
   ```

3. **é…ç½®ä¿¡æ¯**:
   ```bash
   python -c "
   from app.core.config import settings
   print('æ¨¡å‹è·¯å¾„:', settings.embedding_model_path)
   print('æ•°æ®åº“è·¯å¾„:', settings.chroma_db_full_path)
   "
   ```

4. **é‡ç°æ­¥éª¤**: è¯¦ç»†æè¿°å¦‚ä½•é‡ç°é—®é¢˜

### ç´§æ€¥è”ç³»

å¯¹äºç”Ÿäº§ç¯å¢ƒçš„ç´§æ€¥é—®é¢˜ï¼š

1. ç«‹å³åœæ­¢æœåŠ¡ï¼š`pkill -f "python start_server.py"`
2. å¤‡ä»½æ•°æ®ï¼š`cp -r data/chroma_db data/emergency_backup`
3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—ï¼š`tail -n 200 logs/error.log`
4. è”ç³»æŠ€æœ¯æ”¯æŒå¹¶æä¾›å®Œæ•´çš„é”™è¯¯ä¿¡æ¯

---

**æç¤º**: å¤§å¤šæ•°é—®é¢˜éƒ½å¯ä»¥é€šè¿‡æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å’ŒéªŒè¯é…ç½®æ¥è§£å†³ã€‚é‡åˆ°é—®é¢˜æ—¶ï¼Œé¦–å…ˆæŸ¥çœ‹ `logs/app.log` å’Œ `logs/error.log` æ–‡ä»¶ã€‚