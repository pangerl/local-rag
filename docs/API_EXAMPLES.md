# API ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ

æœ¬æ–‡æ¡£æä¾› Local RAG ç³»ç»Ÿ API çš„è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µæŒ‡å—ã€‚

## ğŸ“‹ API æ¦‚è§ˆ

Local RAG ç³»ç»Ÿæä¾›ä¸¤ä¸ªä¸»è¦ API ç«¯ç‚¹ï¼š

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ | ç”¨é€” |
|------|------|------|------|
| `/api/v1/ingest` | POST | æ–‡æ¡£æ‘„å– | ä¸Šä¼ å’Œå¤„ç†æ–‡æ¡£ |
| `/api/v1/retrieve` | POST | æ–‡æ¡£æ£€ç´¢ | æŸ¥è¯¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨ API æœåŠ¡
python start_server.py

# éªŒè¯æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health
```

### æŸ¥çœ‹ API æ–‡æ¡£

è®¿é—® http://localhost:8000/docs æŸ¥çœ‹äº¤äº’å¼ API æ–‡æ¡£ã€‚

## ğŸ“¤ æ–‡æ¡£æ‘„å– API

### åŸºæœ¬ç”¨æ³•

```bash
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{
    "document_path": "documents/example.txt"
  }'
```

### å®Œæ•´å‚æ•°ç¤ºä¾‹

```bash
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{
    "document_path": "documents/technical_manual.txt",
    "chunk_size": 400,
    "chunk_overlap": 80
  }'
```

### Python å®¢æˆ·ç«¯ç¤ºä¾‹

```python
import requests
import json
from pathlib import Path

class LocalRAGClient:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = requests.Session()
    
    def ingest_document(self, document_path: str, chunk_size: int = 300, chunk_overlap: int = 50):
        """æ‘„å–å•ä¸ªæ–‡æ¡£"""
        url = f"{self.base_url}/api/v1/ingest"
        payload = {
            "document_path": document_path,
            "chunk_size": chunk_size,
            "chunk_overlap": chunk_overlap
        }
        
        try:
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"æ‘„å–å¤±è´¥: {e}")
            return None
    
    def ingest_directory(self, directory_path: str, chunk_size: int = 300, chunk_overlap: int = 50):
        """æ‰¹é‡æ‘„å–ç›®å½•ä¸­çš„æ–‡æ¡£"""
        directory = Path(directory_path)
        results = []
        
        for file_path in directory.rglob("*.txt"):
            print(f"å¤„ç†æ–‡ä»¶: {file_path}")
            result = self.ingest_document(str(file_path), chunk_size, chunk_overlap)
            if result:
                results.append(result)
        
        for file_path in directory.rglob("*.md"):
            print(f"å¤„ç†æ–‡ä»¶: {file_path}")
            result = self.ingest_document(str(file_path), chunk_size, chunk_overlap)
            if result:
                results.append(result)
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
client = LocalRAGClient()

# æ‘„å–å•ä¸ªæ–‡æ¡£
result = client.ingest_document("documents/user_manual.txt")
if result:
    print(f"æ‘„å–æˆåŠŸ: {result['chunks_count']} ä¸ªåˆ†ç‰‡")

# æ‰¹é‡æ‘„å–
results = client.ingest_directory("documents/")
print(f"æ‰¹é‡æ‘„å–å®Œæˆ: {len(results)} ä¸ªæ–‡ä»¶")
```

### JavaScript/Node.js ç¤ºä¾‹

```javascript
const axios = require('axios');
const fs = require('fs').promises;
const path = require('path');

class LocalRAGClient {
    constructor(baseURL = 'http://localhost:8000') {
        this.client = axios.create({
            baseURL,
            headers: {
                'Content-Type': 'application/json'
            }
        });
    }

    async ingestDocument(documentPath, chunkSize = 300, chunkOverlap = 50) {
        try {
            const response = await this.client.post('/api/v1/ingest', {
                document_path: documentPath,
                chunk_size: chunkSize,
                chunk_overlap: chunkOverlap
            });
            return response.data;
        } catch (error) {
            console.error('æ‘„å–å¤±è´¥:', error.response?.data || error.message);
            return null;
        }
    }

    async ingestDirectory(directoryPath, chunkSize = 300, chunkOverlap = 50) {
        const results = [];
        const files = await this.getTextFiles(directoryPath);
        
        for (const file of files) {
            console.log(`å¤„ç†æ–‡ä»¶: ${file}`);
            const result = await this.ingestDocument(file, chunkSize, chunkOverlap);
            if (result) {
                results.push(result);
            }
        }
        
        return results;
    }

    async getTextFiles(dir) {
        const files = [];
        const items = await fs.readdir(dir, { withFileTypes: true });
        
        for (const item of items) {
            const fullPath = path.join(dir, item.name);
            if (item.isDirectory()) {
                files.push(...await this.getTextFiles(fullPath));
            } else if (item.name.endsWith('.txt') || item.name.endsWith('.md')) {
                files.push(fullPath);
            }
        }
        
        return files;
    }
}

// ä½¿ç”¨ç¤ºä¾‹
async function main() {
    const client = new LocalRAGClient();
    
    // æ‘„å–å•ä¸ªæ–‡æ¡£
    const result = await client.ingestDocument('documents/example.txt');
    if (result) {
        console.log(`æ‘„å–æˆåŠŸ: ${result.chunks_count} ä¸ªåˆ†ç‰‡`);
    }
    
    // æ‰¹é‡æ‘„å–
    const results = await client.ingestDirectory('documents/');
    console.log(`æ‰¹é‡æ‘„å–å®Œæˆ: ${results.length} ä¸ªæ–‡ä»¶`);
}

main().catch(console.error);
```

## ğŸ“¥ æ–‡æ¡£æ£€ç´¢ API

### åŸºæœ¬ç”¨æ³•

```bash
curl -X POST "http://localhost:8000/api/v1/retrieve" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "å¦‚ä½•é…ç½®ç³»ç»Ÿå‚æ•°ï¼Ÿ"
  }'
```

### å®Œæ•´å‚æ•°ç¤ºä¾‹

```bash
curl -X POST "http://localhost:8000/api/v1/retrieve" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„æœ€ä½³å®è·µ",
    "retrieval_k": 15,
    "top_k": 5
  }'
```

### Python æ£€ç´¢å®¢æˆ·ç«¯

```python
class LocalRAGClient:
    # ... (å‰é¢çš„ä»£ç )
    
    def retrieve(self, query: str, retrieval_k: int = 10, top_k: int = 3):
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        url = f"{self.base_url}/api/v1/retrieve"
        payload = {
            "query": query,
            "retrieval_k": retrieval_k,
            "top_k": top_k
        }
        
        try:
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"æ£€ç´¢å¤±è´¥: {e}")
            return None
    
    def search_and_display(self, query: str, retrieval_k: int = 10, top_k: int = 3):
        """æ£€ç´¢å¹¶æ ¼å¼åŒ–æ˜¾ç¤ºç»“æœ"""
        results = self.retrieve(query, retrieval_k, top_k)
        
        if not results:
            print("æ£€ç´¢å¤±è´¥")
            return
        
        print(f"æŸ¥è¯¢: {query}")
        print(f"æ£€ç´¢æ—¶é—´: {results.get('retrieval_time', 0):.3f}s")
        print("-" * 60)
        
        for i, result in enumerate(results.get('results', []), 1):
            print(f"ç»“æœ {i} (ç›¸å…³æ€§: {result['score']:.3f})")
            print(f"å†…å®¹: {result['content'][:200]}...")
            print(f"æ¥æº: {result['metadata']['file_name']}")
            print(f"åˆ†ç‰‡: {result['metadata']['chunk_index']}")
            print("-" * 60)

# ä½¿ç”¨ç¤ºä¾‹
client = LocalRAGClient()

# ç®€å•æ£€ç´¢
results = client.retrieve("Python ç¼–ç¨‹æŠ€å·§")

# æ ¼å¼åŒ–æ˜¾ç¤º
client.search_and_display("æ•°æ®åº“ä¼˜åŒ–æ–¹æ³•", retrieval_k=15, top_k=5)
```

### æ‰¹é‡æŸ¥è¯¢ç¤ºä¾‹

```python
def batch_query(client, queries, output_file="query_results.json"):
    """æ‰¹é‡æŸ¥è¯¢å¹¶ä¿å­˜ç»“æœ"""
    all_results = {}
    
    for query in queries:
        print(f"æŸ¥è¯¢: {query}")
        results = client.retrieve(query)
        if results:
            all_results[query] = results
    
    # ä¿å­˜ç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"æ‰¹é‡æŸ¥è¯¢å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_file}")
    return all_results

# ä½¿ç”¨ç¤ºä¾‹
queries = [
    "å¦‚ä½•ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½ï¼Ÿ",
    "æœºå™¨å­¦ä¹ æ¨¡å‹è¯„ä¼°æŒ‡æ ‡",
    "Python å¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ",
    "å¾®æœåŠ¡æ¶æ„è®¾è®¡åŸåˆ™"
]

client = LocalRAGClient()
batch_results = batch_query(client, queries)
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ–‡æ¡£æ‘„å–æœ€ä½³å®è·µ

#### æ–‡æ¡£å‡†å¤‡

```python
def prepare_documents(source_dir, target_dir):
    """æ–‡æ¡£é¢„å¤„ç†"""
    import shutil
    from pathlib import Path
    
    source = Path(source_dir)
    target = Path(target_dir)
    target.mkdir(exist_ok=True)
    
    for file_path in source.rglob("*"):
        if file_path.is_file():
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            if file_path.suffix.lower() in ['.txt', '.md']:
                # æ£€æŸ¥æ–‡ä»¶ç¼–ç 
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # æ¸…ç†å†…å®¹
                    content = clean_text(content)
                    
                    # ä¿å­˜åˆ°ç›®æ ‡ç›®å½•
                    target_file = target / file_path.name
                    with open(target_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    print(f"å¤„ç†å®Œæˆ: {file_path.name}")
                    
                except UnicodeDecodeError:
                    print(f"ç¼–ç é”™è¯¯ï¼Œè·³è¿‡: {file_path}")

def clean_text(text):
    """æ–‡æœ¬æ¸…ç†"""
    import re
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', '', text)
    
    # ç§»é™¤è¿‡çŸ­çš„è¡Œ
    lines = [line.strip() for line in text.split('\n') if len(line.strip()) > 10]
    
    return '\n'.join(lines)
```

#### åˆ†ç‰‡ç­–ç•¥é€‰æ‹©

```python
def choose_chunk_params(document_type, content_length):
    """æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©åˆ†ç‰‡å‚æ•°"""
    
    if document_type == "technical_manual":
        return {"chunk_size": 400, "chunk_overlap": 80}
    elif document_type == "conversation":
        return {"chunk_size": 200, "chunk_overlap": 40}
    elif document_type == "academic_paper":
        return {"chunk_size": 500, "chunk_overlap": 100}
    elif content_length < 1000:
        return {"chunk_size": 150, "chunk_overlap": 30}
    else:
        return {"chunk_size": 300, "chunk_overlap": 50}  # é»˜è®¤å€¼

# ä½¿ç”¨ç¤ºä¾‹
def smart_ingest(client, file_path, document_type="general"):
    """æ™ºèƒ½æ‘„å–"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    params = choose_chunk_params(document_type, len(content))
    return client.ingest_document(file_path, **params)
```

### 2. æ£€ç´¢ä¼˜åŒ–æœ€ä½³å®è·µ

#### æŸ¥è¯¢ä¼˜åŒ–

```python
def optimize_query(query):
    """æŸ¥è¯¢ä¼˜åŒ–"""
    import jieba
    
    # åˆ†è¯
    words = list(jieba.cut(query))
    
    # ç§»é™¤åœç”¨è¯
    stopwords = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
    words = [w for w in words if w not in stopwords and len(w) > 1]
    
    # é‡æ–°ç»„åˆ
    optimized_query = ' '.join(words)
    return optimized_query

def semantic_search(client, query, context_window=2):
    """è¯­ä¹‰æœç´¢å¢å¼º"""
    # ä¼˜åŒ–æŸ¥è¯¢
    optimized_query = optimize_query(query)
    
    # æ‰§è¡Œæ£€ç´¢
    results = client.retrieve(optimized_query, retrieval_k=20, top_k=10)
    
    if not results:
        return None
    
    # åå¤„ç†ï¼šåˆå¹¶ç›¸é‚»åˆ†ç‰‡
    enhanced_results = []
    for result in results['results']:
        # è·å–ä¸Šä¸‹æ–‡åˆ†ç‰‡
        context = get_context_chunks(result, context_window)
        result['enhanced_content'] = context
        enhanced_results.append(result)
    
    return enhanced_results

def get_context_chunks(result, window_size):
    """è·å–ä¸Šä¸‹æ–‡åˆ†ç‰‡"""
    # è¿™é‡Œéœ€è¦å®ç°è·å–ç›¸é‚»åˆ†ç‰‡çš„é€»è¾‘
    # ç®€åŒ–ç¤ºä¾‹
    return result['content']
```

#### ç»“æœåå¤„ç†

```python
def post_process_results(results, query):
    """ç»“æœåå¤„ç†"""
    if not results or 'results' not in results:
        return results
    
    processed_results = []
    
    for result in results['results']:
        # è®¡ç®—æŸ¥è¯¢è¯è¦†ç›–ç‡
        coverage = calculate_query_coverage(result['content'], query)
        result['query_coverage'] = coverage
        
        # æ·»åŠ æ‘˜è¦
        result['summary'] = generate_summary(result['content'])
        
        # é«˜äº®å…³é”®è¯
        result['highlighted_content'] = highlight_keywords(result['content'], query)
        
        processed_results.append(result)
    
    # é‡æ–°æ’åº
    processed_results.sort(key=lambda x: (x['score'] * 0.7 + x['query_coverage'] * 0.3), reverse=True)
    
    results['results'] = processed_results
    return results

def calculate_query_coverage(content, query):
    """è®¡ç®—æŸ¥è¯¢è¯è¦†ç›–ç‡"""
    import jieba
    
    query_words = set(jieba.cut(query))
    content_words = set(jieba.cut(content))
    
    if not query_words:
        return 0.0
    
    coverage = len(query_words & content_words) / len(query_words)
    return coverage

def generate_summary(content, max_length=100):
    """ç”Ÿæˆå†…å®¹æ‘˜è¦"""
    if len(content) <= max_length:
        return content
    
    # ç®€å•çš„æ‘˜è¦ç”Ÿæˆï¼šå–å‰é¢çš„å¥å­
    sentences = content.split('ã€‚')
    summary = ""
    for sentence in sentences:
        if len(summary + sentence) <= max_length:
            summary += sentence + "ã€‚"
        else:
            break
    
    return summary.strip()

def highlight_keywords(content, query):
    """é«˜äº®å…³é”®è¯"""
    import jieba
    import re
    
    query_words = list(jieba.cut(query))
    highlighted = content
    
    for word in query_words:
        if len(word) > 1:  # å¿½ç•¥å•å­—ç¬¦
            pattern = re.escape(word)
            highlighted = re.sub(pattern, f"**{word}**", highlighted)
    
    return highlighted
```

### 3. æ€§èƒ½ä¼˜åŒ–

#### è¿æ¥æ± ç®¡ç†

```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class OptimizedRAGClient:
    def __init__(self, base_url="http://localhost:8000", max_retries=3):
        self.base_url = base_url
        self.session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=max_retries,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        
        # é…ç½®è¿æ¥æ± 
        adapter = HTTPAdapter(
            max_retries=retry_strategy,
            pool_connections=10,
            pool_maxsize=20
        )
        
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # è®¾ç½®è¶…æ—¶
        self.session.timeout = 30

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.session.close()
```

#### å¹¶å‘å¤„ç†

```python
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor

class AsyncRAGClient:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
    
    async def ingest_document_async(self, session, document_path, chunk_size=300, chunk_overlap=50):
        """å¼‚æ­¥æ–‡æ¡£æ‘„å–"""
        url = f"{self.base_url}/api/v1/ingest"
        payload = {
            "document_path": document_path,
            "chunk_size": chunk_size,
            "chunk_overlap": chunk_overlap
        }
        
        try:
            async with session.post(url, json=payload) as response:
                return await response.json()
        except Exception as e:
            print(f"æ‘„å–å¤±è´¥ {document_path}: {e}")
            return None
    
    async def batch_ingest_async(self, document_paths, chunk_size=300, chunk_overlap=50):
        """å¼‚æ­¥æ‰¹é‡æ‘„å–"""
        async with aiohttp.ClientSession() as session:
            tasks = [
                self.ingest_document_async(session, path, chunk_size, chunk_overlap)
                for path in document_paths
            ]
            results = await asyncio.gather(*tasks)
            return [r for r in results if r is not None]

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    client = AsyncRAGClient()
    document_paths = ["doc1.txt", "doc2.txt", "doc3.txt"]
    results = await client.batch_ingest_async(document_paths)
    print(f"æ‰¹é‡æ‘„å–å®Œæˆ: {len(results)} ä¸ªæ–‡ä»¶")

# asyncio.run(main())
```

### 4. é”™è¯¯å¤„ç†å’Œé‡è¯•

```python
import time
from functools import wraps

def retry_on_failure(max_retries=3, delay=1, backoff=2):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            current_delay = delay
            
            while retries < max_retries:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    retries += 1
                    if retries >= max_retries:
                        raise e
                    
                    print(f"æ“ä½œå¤±è´¥ï¼Œ{current_delay}ç§’åé‡è¯• ({retries}/{max_retries}): {e}")
                    time.sleep(current_delay)
                    current_delay *= backoff
            
            return None
        return wrapper
    return decorator

class RobustRAGClient(LocalRAGClient):
    @retry_on_failure(max_retries=3, delay=1)
    def ingest_document(self, document_path, chunk_size=300, chunk_overlap=50):
        """å¸¦é‡è¯•çš„æ–‡æ¡£æ‘„å–"""
        return super().ingest_document(document_path, chunk_size, chunk_overlap)
    
    @retry_on_failure(max_retries=3, delay=0.5)
    def retrieve(self, query, retrieval_k=10, top_k=3):
        """å¸¦é‡è¯•çš„æ–‡æ¡£æ£€ç´¢"""
        return super().retrieve(query, retrieval_k, top_k)
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å“åº”æ—¶é—´ç›‘æ§

```python
import time
from contextlib import contextmanager

@contextmanager
def timer(operation_name):
    """è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start_time = time.time()
    try:
        yield
    finally:
        end_time = time.time()
        print(f"{operation_name} è€—æ—¶: {end_time - start_time:.3f}s")

# ä½¿ç”¨ç¤ºä¾‹
client = LocalRAGClient()

with timer("æ–‡æ¡£æ‘„å–"):
    result = client.ingest_document("large_document.txt")

with timer("æ–‡æ¡£æ£€ç´¢"):
    results = client.retrieve("å¤æ‚æŸ¥è¯¢é—®é¢˜")
```

### æ‰¹é‡æ€§èƒ½æµ‹è¯•

```python
def performance_test(client, test_queries, iterations=10):
    """æ€§èƒ½æµ‹è¯•"""
    import statistics
    
    response_times = []
    
    for i in range(iterations):
        for query in test_queries:
            start_time = time.time()
            result = client.retrieve(query)
            end_time = time.time()
            
            if result:
                response_times.append(end_time - start_time)
    
    if response_times:
        avg_time = statistics.mean(response_times)
        median_time = statistics.median(response_times)
        max_time = max(response_times)
        min_time = min(response_times)
        
        print(f"æ€§èƒ½æµ‹è¯•ç»“æœ ({len(response_times)} æ¬¡è¯·æ±‚):")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
        print(f"  ä¸­ä½æ•°å“åº”æ—¶é—´: {median_time:.3f}s")
        print(f"  æœ€å¤§å“åº”æ—¶é—´: {max_time:.3f}s")
        print(f"  æœ€å°å“åº”æ—¶é—´: {min_time:.3f}s")

# ä½¿ç”¨ç¤ºä¾‹
test_queries = [
    "ç³»ç»Ÿé…ç½®æ–¹æ³•",
    "æ€§èƒ½ä¼˜åŒ–æŠ€å·§",
    "é”™è¯¯å¤„ç†ç­–ç•¥"
]

client = LocalRAGClient()
performance_test(client, test_queries)
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§ API é”™è¯¯

```python
def handle_api_errors(response):
    """å¤„ç† API é”™è¯¯"""
    if response.status_code == 200:
        return response.json()
    
    error_messages = {
        400: "è¯·æ±‚å‚æ•°é”™è¯¯",
        404: "æ–‡æ¡£æœªæ‰¾åˆ°",
        422: "å‚æ•°éªŒè¯å¤±è´¥",
        500: "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"
    }
    
    error_msg = error_messages.get(response.status_code, f"æœªçŸ¥é”™è¯¯ ({response.status_code})")
    
    try:
        error_detail = response.json()
        print(f"API é”™è¯¯: {error_msg}")
        print(f"è¯¦ç»†ä¿¡æ¯: {error_detail}")
    except:
        print(f"API é”™è¯¯: {error_msg}")
        print(f"å“åº”å†…å®¹: {response.text}")
    
    return None

# åœ¨å®¢æˆ·ç«¯ä¸­ä½¿ç”¨
class SafeRAGClient(LocalRAGClient):
    def _make_request(self, method, url, **kwargs):
        """å®‰å…¨çš„è¯·æ±‚æ–¹æ³•"""
        try:
            response = self.session.request(method, url, **kwargs)
            return handle_api_errors(response)
        except requests.exceptions.ConnectionError:
            print("è¿æ¥é”™è¯¯: æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯åŠ¨")
            return None
        except requests.exceptions.Timeout:
            print("è¶…æ—¶é”™è¯¯: è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
            return None
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {e}")
            return None
```

---

**æç¤º**: è¿™äº›ç¤ºä¾‹å±•ç¤ºäº† Local RAG ç³»ç»Ÿ API çš„å„ç§ä½¿ç”¨æ–¹å¼ã€‚æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ–¹æ³•ï¼Œå¹¶æ³¨æ„é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–ã€‚